{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from collections import deque\n",
    "import random\n",
    "import sklearn.ensemble\n",
    "import sklearn.tree\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import sklearn.multioutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Trees Q-learning implementation #\n",
    "################################\n",
    "\n",
    "env.reset()\n",
    "observation_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "EXPLORATION_MIN = 1\n",
    "EXPLORATION_DECAY = 0.96\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.95\n",
    "\n",
    "exploration_rate = 1\n",
    "memory = deque(maxlen=1000)\n",
    "\n",
    "forest = sklearn.ensemble.GradientBoostingRegressor(n_estimators=100,random_state=0)\n",
    "classifier = sklearn.multioutput.MultiOutputRegressor(forest)\n",
    "\n",
    "def select_action(state):\n",
    "    global exploration_rate\n",
    "    \n",
    "    if np.random.rand() < exploration_rate:\n",
    "        return action_space.sample()\n",
    "    try:\n",
    "        q_values = classifier.predict(state.reshape(1, -1))\n",
    "        return np.argmax(q_values[0])\n",
    "    except NotFittedError as e:\n",
    "        return 0\n",
    "\n",
    "def remember(last_state,action,reward,next_state,done):\n",
    "    global memory\n",
    "    memory.append((last_state,action,reward,next_state,done))\n",
    "\n",
    "def experience_replay():\n",
    "    global memory,EXPLORATION_MIN,EXPLORATION_DECAY,BATCH_SIZE,GAMMA,exploration_rate\n",
    "\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "#     batch = random.sample(memory,BATCH_SIZE)\n",
    "    batch = memory\n",
    "    \n",
    "    X = np.empty((0,4))\n",
    "    y = np.empty((0,2))\n",
    "    for last_state, action, reward, next_state, done in batch:\n",
    "        q_update = reward\n",
    "        if not done:\n",
    "            try:\n",
    "                q_update = (reward + GAMMA * np.amax(classifier.predict(next_state.reshape(1, -1))[0]))\n",
    "            except NotFittedError as e:\n",
    "                q_update = reward \n",
    "        try:\n",
    "            q_values = classifier.predict(last_state.reshape(1, -1))\n",
    "        except NotFittedError as e:\n",
    "            q_values = np.zeros(action_space.n).reshape(1, -1)\n",
    "        q_values[0][action] = q_update\n",
    "        \n",
    "        X = np.append(X,np.array([last_state]),axis=0)\n",
    "        y = np.append(y,np.array([q_values[0]]),axis=0)\n",
    "    \n",
    "    #fit\n",
    "    classifier.fit(X,y)\n",
    "    \n",
    "    if exploration_rate > EXPLORATION_MIN:\n",
    "        exploration_rate *= EXPLORATION_DECAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 13 steps with 11.0 total reward\n",
      "Episode 1 finished after 11 steps with 9.0 total reward\n",
      "Episode 2 finished after 23 steps with 21.0 total reward\n",
      "Episode 3 finished after 17 steps with 15.0 total reward\n",
      "Episode 4 finished after 23 steps with 21.0 total reward\n",
      "Episode 5 finished after 24 steps with 22.0 total reward\n",
      "Episode 6 finished after 45 steps with 43.0 total reward\n",
      "Episode 7 finished after 11 steps with 9.0 total reward\n",
      "Episode 8 finished after 16 steps with 14.0 total reward\n",
      "Episode 9 finished after 10 steps with 8.0 total reward\n",
      "Episode 10 finished after 16 steps with 14.0 total reward\n",
      "Episode 11 finished after 13 steps with 11.0 total reward\n",
      "Episode 12 finished after 35 steps with 33.0 total reward\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "episodes = 100\n",
    "episodes_steps = np.array([])\n",
    "num_solved = 0\n",
    "\n",
    "for episode_i in range(episodes):\n",
    "    last_state = env.reset()\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while True:\n",
    "#         env.render()\n",
    "        steps += 1\n",
    "        action = select_action(last_state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        reward = reward if not done else -reward\n",
    "        remember(last_state,action,reward,next_state,done)\n",
    "        experience_replay()\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} steps with {} total reward\".format(episode_i,steps,total_reward))\n",
    "            if total_reward > 250:\n",
    "                num_solved += 1\n",
    "            break\n",
    "    \n",
    "        last_state = next_state\n",
    "    \n",
    "    episodes_steps = np.append(episodes_steps,steps)\n",
    "    \n",
    "    if num_solved > 10:\n",
    "        break\n",
    "        \n",
    "env.close()\n",
    "\n",
    "plt.plot(episodes_steps)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
